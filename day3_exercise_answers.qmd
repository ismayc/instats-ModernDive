---
title: "Statistics in R with the `tidyverse`"
author: "Dr. Chester Ismay"
subtitle: "Day 3 Exercises"
format: html
---

```{r}
#| include: false
options(width = 120)
```


# Day 3: Sampling and Estimation in R

## Session 1: Sampling

### 1. Load Necessary Packages

```{r}
# Load the required packages
library(dplyr)
library(ggplot2)
library(moderndive)
library(infer)
```

- These packages provide tools for data wrangling, visualization, and modeling.  

---

### 2. Prepare Population Dataset with Generation

```{r}
# For reproducibility
set.seed(2024)

# Create vectors of sport ball types and their proportions
types_of_sport_balls <- c("Basketball", "Pickleball", "Tennis Ball", 
                          "Football/Soccer", "American Football")
proportion_of_each_type <- c(0.2, 0.15, 0.3, 0.25, 0.1)

# Create a tibble of 1200 sport balls that will act as our population
store_ball_inventory <- tibble(
  ball_ID = 1:1200,
  ball_type = sample(x = types_of_sport_balls,
                     size = 1200, 
                     replace = TRUE, 
                     prob = proportion_of_each_type
  )
)
```

- We'll be exploring a synthesized data set of an inventory at a large sporting goods store. The inventory pertains to different types of sports balls, 1200 in total.

---

### 3. Exploring Dataset Structure

```{r}
# Use glimpse to explore the structure of the dataset
glimpse(store_ball_inventory)
```


---

### 4. Population Parameters

```{r}
# Create a count of ball_type
store_ball_inventory |> 
  count(ball_type)

# Determine the proportion of basketballs in the inventory
p_df <- store_ball_inventory |> 
  summarize(prop_bball = mean(ball_type == "Basketball"))

# Convert p to a numeric value
p <- p_df$prop_bball

# Or using the tidyverse
p <- p_df |> pull(prop_bball)
p
```


---

### 5. Take a Sample of Balls

```{r}
# Retrieve a sample of 10 balls from the inventory
ball_sample <- store_ball_inventory |> 
  slice_sample(n = 10, replace = FALSE)

# Determine the proportion of basketballs in the sample
ball_sample |> 
  summarize(prop_bball = mean(ball_type == "Basketball"))
```

---

### 6. Take Another Sample of Balls

```{r}
# Retrieve another sample of 50 balls from the inventory
ball_sample2 <- store_ball_inventory |> 
  slice_sample(n = 10, replace = FALSE)

# Determine the proportion of pickleballs in the sample
ball_sample2 |> 
  summarize(prop_bball = mean(ball_type == "Basketball"))
```


---

### 7. Take 1000 Samples of Size 10 from the Population

```{r}
# Use `rep_slice_sample()` from the `infer` package
ball_samples <- store_ball_inventory |> 
  rep_slice_sample(n = 10, reps = 1000, replace = FALSE)
ball_samples
```


---

### 8. Calculate Sample Proportions and Visualize Them

```{r}
# Determine sample proportions with `dplyr`
props_bball <- ball_samples |> 
  summarize(prop_bball = mean(ball_type == "Basketball"))

# Create a histogram of the sample proportions with 8 bins
ggplot(props_bball, aes(x = prop_bball)) +
  geom_histogram(bins = 8, color = "white") +
  labs(x = "Sample proportion", 
       title = "Histogram of 1000 sample proportions of Basketballs") 

```


---

### 9. Determine a Guess at the Standard Error

```{r}
# Using the simulations, calculate the standard deviation of the 
# sample proportions
se_sample_props <- props_bball |> 
  summarize(sd(prop_bball)) |> 
  pull()

# Using the formula for the standard error of a sample proportion
n <- 10
se_sample_props_formula <- sqrt(p * (1 - p) / n)
se_sample_props_formula
```

### 10. Use Function from Walkthrough to Calculate Standard Error

```{r}
# Here's the function from the walkthrough to calculate the standard error
se_sample_props <- function(size, repetitions = 1000, type = "Pickleball") {
  props <- store_ball_inventory |> 
    rep_slice_sample(n = size, reps = repetitions, replace = FALSE) |> 
    summarize(prop = mean(ball_type == type))
  
  se_sample_props <- props |> 
    summarize(sd(prop)) |> 
    pull()
  
  return(se_sample_props)
}

# Use the function to calculate the standard error for a sample size of 10
# with 2000 repetitions for Basketball
se_sample_props(10, 2000, "Basketball")
```

---

## Session 2: Estimation using Theory-based Methods

### 11. Population Data with Numeric Variable of Interest

Assume we have information about the population of homes in Phoenix, AZ. We
are interested in their use of electricity factoring in that some homes
do not have air conditioning and only use fans.

```{r}
# For reproducibility
set.seed(2024)

# Number of homes in each group
n_ac <- 0.8 * 600000
n_fans <- 0.2 * 600000

# Simulate electricity usage (in kWh) for homes with AC
ac_usage <- rnorm(n_ac, mean = 1500, sd = 300)  # Higher mean for AC usage

# Simulate electricity usage (in kWh) for homes using fans
fan_usage <- rnorm(n_fans, mean = 800, sd = 150)  # Lower mean for fan usage

# Combine into a single data frame
electricity_usage_phoenix <- tibble(
  home_ID = 1:(n_ac + n_fans),
  cooling_system = c(rep("AC", n_ac), rep("Fans", n_fans)),
  usage_kWh = c(ac_usage, fan_usage)
)

# View the data
electricity_usage_phoenix
```

### 12. The Sample and the Sample Statistic

```{r}
# Choose sample size
sample_size <- 1000

# Generate a sample
set.seed(2024)
usage_sample <- electricity_usage_phoenix |> 
  slice_sample(n = sample_size, replace = FALSE)

# Calculate the sample mean
sample_mean <- usage_sample |> 
  summarize(mean(usage_kWh)) |> 
  pull()
sample_mean

# Calculate the standard deviation 
sample_sd <- usage_sample |> 
  summarize(sd(usage_kWh)) |> 
  pull()
sample_sd
```


### 13. Population Parameter

```{r}
# Calculate the population mean
population_mean <- electricity_usage_phoenix |> 
  summarize(mean(usage_kWh)) |> 
  pull()
mu <- population_mean
mu

# Calculate the population standard deviation
population_sd <- electricity_usage_phoenix |> 
  summarize(sd(usage_kWh)) |> 
  pull()
sigma <- population_sd
sigma
```

### 14. Confidence Interval for the Population Proportion (Assuming We Know $\sigma$)

```{r}
# Calculate the margin of error for a 90% confidence interval
z_star <- qnorm(p = 0.95) # Assumes a normal distribution
margin_of_error <- z_star * (sigma / sqrt(sample_size))

# Recall the point estimate
point_estimate <- sample_mean

# Calculate the confidence interval
lower_bound <- point_estimate - margin_of_error
upper_bound <- point_estimate + margin_of_error

# Display the confidence interval
c(lower_bound, upper_bound)

# Remember the population parameter (we usually don't know it)
between(mu, lower_bound, upper_bound) # dplyr::between()
```

### 15. Confidence Interval for the Population Proportion (Assuming We Don't Know $\sigma$)

```{r}
# Calculate the margin of error for a 90% confidence interval
t_star <- qt(p = 0.95, df = sample_size - 1) # t-distribution
margin_of_error_t <- t_star * (sample_sd / sqrt(sample_size))

# Same point estimate
point_estimate_t <- sample_mean

# Calculate the confidence interval
lower_bound_t <- point_estimate_t - margin_of_error_t
upper_bound_t <- point_estimate_t + margin_of_error_t

# Display the confidence interval
c(lower_bound_t, upper_bound_t)

# Remember the population parameter (we usually don't know it)
between(mu, lower_bound_t, upper_bound_t)
```

### 16. Interpreting the Confidence Interval

We are "95% confident" that the true mean commute time for this population of Phoenix houses is between `r lower_bound_t` and `r upper_bound_t` kilowatt-hours. This is the same as saying that if we were to take many samples of size 100 and calculate the confidence interval for each sample, we would expect 95% of those intervals to contain the true population mean of `r mu`.

---

## Session 3: Estimation via Bootstrapping Methods

### 17. Assume We Only Have A Sample

```{r}
# Assume we only have a sample of 1000 homes and their electricity usage
usage_sample
```

---

### 18. Going Over the `infer` Framework

#### Describe each step in the `infer` framework you have seen so far to calculate bootstrap statistics

Start with the `data` and then `|>` into the following functions:  
- `specify()`: Define the variable of interest  
- `generate()`: Create the bootstrap samples  
- `calculate()`: Calculate the statistic of interest  
- `visualize()`: Visualize the bootstrap distribution  

---

### 19. Bootstrapping the Sample

```{r}
# Bootstrapping the sample
set.seed(2024)
one_bootstrap <- usage_sample |> 
  specify(response = usage_kWh) |> 
  generate(reps = 1, type = "bootstrap")
one_bootstrap
```

---

### 20. Determine the Mean of the Bootstrap Sample

```{r}
# Calculate the mean of the bootstrap sample
one_bootstrap |> 
  calculate(stat = "mean") |> 
  pull()
```

---

### 21. Bootstrapping 1000 Samples

```{r}
# Bootstrapping 1000 samples
many_bootstraps <- usage_sample |> 
  specify(response = usage_kWh) |> 
  generate(reps = 1000, type = "bootstrap")
many_bootstraps
```

### 22. Get the Mean of Each Bootstrap Sample

```{r}
# Calculate the mean of each bootstrap sample
bootstrap_means <- many_bootstraps |> 
  calculate(stat = "mean")
bootstrap_means
```

---

### 23. Visualizing the Bootstrap Distribution

```{r}
# Create a histogram of the bootstrap means
ggplot(bootstrap_means, aes(x = stat)) +
  geom_histogram(bins = 30, color = "white") +
  labs(x = "Bootstrap sample mean", 
       title = "Histogram of 1000 bootstrap sample means")
```

---

### 24. Calculate the Bootstrap Confidence Interval

```{r}
# Calculate the 90% bootstrap confidence interval in two ways since bell-shaped
bootstrap_percentile_ci <- bootstrap_means |> 
  get_confidence_interval(level = 0.90, type = "percentile")

bootstrap_se_ci <- bootstrap_means |> 
  get_confidence_interval(level = 0.90, 
                          type = "se",
                          point_estimate = sample_mean)
```

---

### 25. Interpretation of the Bootstrap Confidence Interval

We are "95% confident" that the true mean electricity usage for this population of adults is between `r bootstrap_percentile_ci$lower_ci` and `r bootstrap_percentile_ci$upper_ci` kilowatt-hours. This is the same as saying that if we were to take many samples of size 100 and calculate the confidence interval for each sample, we would expect 95% of those intervals to contain the true population mean of `r mu`.

---

### 26. Visualize Confidence Interval on Top of Bootstrap Distribution

```{r}
# Show the histogram of bootstrap means with the confidence interval
# and the population parameter (not usually known)
bootstrap_means |> 
  visualize() +
  shade_confidence_interval(endpoints = bootstrap_percentile_ci) +
  geom_vline(xintercept = mu, color = "purple", linewidth = 2)
```
